\documentclass{beamer}

\title{PageRank}
\author{Ben Burns, Dan Magazu, Lucas Chagas, \\Thomas Webster, Trung Do}
\date{Fall 2021}

\usepackage{outlines}
\usepackage{graphicx}
\usepackage{color, xcolor, mdframed}

\graphicspath{{./images}}

\addtobeamertemplate{navigation symbols}{}{%
    \usebeamerfont{footline}%
    \usebeamercolor[fg]{footline}%
    \hspace{1em}%
    \insertframenumber/\inserttotalframenumber
}

\begin{document}

\frame{\titlepage}

\begin{frame}
\frametitle{Table of Contents}
\tableofcontents
\end{frame}

\section{Motivation}
\begin{frame}[t]
\frametitle{Motivation}
\begin{itemize}
    \setlength\itemsep{0.5em}
    \item Problem: the internet has a \emph{lot} of web pages
    \item A lot of the information out there either isn't relevant to us, or is inaccurate
    \item Motivation: we want a program that, when provided a phrase, returns webpages with information relevant to the input
    \item Intuitive solution: return back websites that either contain that phrase, or contain similar phrases
    \item This helps us find more \emph{relevant} pages, but we can't know if we're getting the best information (much less \emph{accurate} information) without manually going through each result
    \item We desire a stronger solution
\end{itemize}
\end{frame}

\section{Background}
\begin{frame}[t]
\frametitle{PageRank}
\begin{outline}
    \1 Invented by Sergey Brin and Larry Page (1998)\footnotemark 
        \2 Publication marks them becoming co-founders of Google  
    \1 Idea: we want some way to numerically score each webpage based on how "important" it is
    \1 Algorithm numerically scores each page $p$ based on 
        \2 How many other pages link to $p$ (or "cite" it)
        \2 The "importance" of each of $p$'s citations 
    \1 We then numerically order pages to rank them
    \1 PageRank: the procedure for scoring each website
    \1 Google: the database that indexes the PageRank of each website for search
\end{outline}
\footnotetext[1]{Many use the year of the original manuscript, 1996}
\end{frame}

\begin{frame}[t]
\frametitle{Underlying Assumptions}    
\begin{outline}
    \1 Running our basic search engine gives us a collection of pages with information relevant to our query
    \1 Assumption: More "important" and useful websites will be the ones with proportionally more inbound links
    \1 Pages with very reliable, primary information are likely to be cited by lots of website authors, and therefore will have lots of "flow" into them
    \1 Assumption: websites with no outgoing links are treated as linking to every other website
    \1 Else, these pages would just take in flow without ever redistrubting, and eventually all users get stuck on these pages
%    \1 If what you're looking for is very niche and therefore won't have many inbound links, the best results will still have proprotionally more citations than other relevant sources
\end{outline}
\end{frame}

\begin{frame}[t]
\frametitle{Finding Less Important Information}
\begin{outline}
    \1 A worry you may have is that we'll only find pages with lots of inbound links
    \1 You can still find niche information by making your query more specific so that it won't match more general pages
    \1 Searching "PageRank" will likely get you Wikipedia, but "Anatomy of PageRank architecture" gives you the original research literature. 
    \1 Your returned urls are still proportionally important results, your query just filtered out the numerically more "important", yet less relevant pages.
\end{outline}
\end{frame}

\section{Formalizing PageRank}
\begin{frame}[t]
\frametitle{Formalizing the PageRank problem}
\begin{outline}
    \1 We're going to construct a directed graph $G = (V, E)$
    \1 For each website we consider, we construct a node $v_i \in V$
    \1 For two distinct nodes $v_i,\ v_j \in V$, the \emph{directed} edge $v_iv_j \in E$ iff there is a link on website $i$ that goes to website $j$.
    \1 If $v_i$ and $v_j$ are not distinct (a website is linking to itself), we ignore the link and do not construct a loop edge.
        \2 $G$ is not a psuedograph
    \1 Multiple hyperlinks on page $i$ to page $j$ are all represented by the single, directed edge 
        \2 $G$ is not a multigraph.
\end{outline}
\end{frame}

\begin{frame}
\frametitle{Visual Representation}
\begin{center}
    \includegraphics[width=0.6\textwidth]{unweighted.png}
\end{center}
\begin{outline}
    \1 We have a set of 4 websites
    \1 Each edge represents a hyperlink from the origin node to the destination node 
\end{outline}
\end{frame}

%\begin{frame}
%\frametitle{Adjacency Matrix}
%\begin{columns}
%    \begin{column}{0.5\textwidth}
%        \centering
%        \includegraphics[width=\textwidth]{unweighted.png}
%    \end{column}
%    \begin{column}{0.5\textwidth}
%        \centering
%        {\Large$A = \begin{pmatrix}
%            0 & 1 & 1 & 1\\
%            0 & 0 & 1 & 1\\
%            1 & 0 & 0 & 0\\
%            1 & 0 & 1 & 0\\
%        \end{pmatrix}$}
%    \end{column}
%\end{columns}
%\begin{outline}
%    \1 No self loops means the main diagonal is all zeros
%\end{outline}
%\end{frame}

\begin{frame}[t]
\frametitle{Applying PageRank Values}
\begin{outline}
    \1 At first, we assign each vertex $v\in V$ with a weight of $\dfrac{1}{|V|}$. 
    \1 All vertices have equal weight, and our weights sum up to 1. The weight of a particular vertex $v_i$ is denoted $PR(v_i)$.
    \1 Consider the set $V_i$ of vertices that $v_i$ has an edge to:
        \2 $V_i = \{v_j | v_iv_j \in E\}$
    \1 A user on page 1 can choose to click a link to traverse to either 2, 3, or 4. In other words, $V_1 = \{2, 3, 4\}$.
%    \1 For each vertex in the set, the weight of the edge to that vertex will be the PageRank value of the source node divided by the number of outbound edges it has
%        \2 $\forall v_j \in V_i: w(v_iv_j) = \dfrac{PR(v_i)}{|V_i|}$
%    \1 In other words, all the outbound edges from a particular vertex will have the same weight
\end{outline}
\begin{center}
    \includegraphics[width=0.4\textwidth]{unweighted.png}
\end{center}
\end{frame}

\begin{frame}[t]
\frametitle{Traversing from Page to Page}
\begin{itemize}
    \setlength\itemsep{1em}
    \item Assumption: A user on page $i$ user is equally likely to choose to visit each vertex in $V_i$ (our set of vertices that $v_i$ cites)
    \item In our example from before, the probabilty that our user on page 1 visits page 2 is $P(v_2) = \dfrac{1}{|V_1|} = \dfrac{1}{3}$
    \item So a third of page 1's visitors will "flow" to page 2, a third to page 3, and a third to page 4
    \item From $v_i$, $P(v_j) = \dfrac{1}{|V_i|}$ if $v_j \in V_i$, and 0 else.
\end{itemize}
\end{frame}

\begin{frame}[t]
\frametitle{Iteration Model}
\begin{outline}
    \1 All at once, all users will click one of the links on their current page
    \1 At "click 0", the PageRank value of all vertices $PR(v) = \dfrac{1}{|V|}$
    \1 On click 1, each page will equally split its PageRank value among the pages it cites
    \1 Page 1 starts with $PR(v_1) = \dfrac{1}{4}$ at click 0, and contributes $\dfrac{1}{12}$ to each of 2, 3, and 4 on click 1
    \1 Conversely, page 1 will receive nothing from page 2, all of $PR(v_3)$, and half of $PR(v_4)$. So after click 1, $PR(v_1) = 0\cdot PR(v_2) + PR(v_3) + \dfrac{1}{2}PR(v_4) = \dfrac{1}{4} + \dfrac{1}{8} = \dfrac{3}{8}$
%    \1 After click $n$, $PR(v_1) = \dfrac{1}{|V_2|}PR(v_2) + \dfrac{1}{|V_3|}PR(v_3) + \dfrac{1}{|V_4|}PR(v_4)$
\end{outline}
\end{frame}

\begin{frame}
\frametitle{Example iterations}
\bgroup
\def\arraystretch{2.5}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
    \hline
    $PR$ & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7\\
    \hline
    $v_1$ & $\dfrac{1}{4}$ & $\dfrac{3}{8}$ & $\dfrac{7}{16}$ & 0.3542 & 0.3958 & 0.3906& 0.3819 & 0.3898\\
    $v_2$ & $\dfrac{1}{4}$ & $\dfrac{1}{12}$ & $\dfrac{1}{8}$ & 0.1458 & 0.1181 & 0.1319& 0.1302 & 0.1273\\
    $v_3$ & $\dfrac{1}{4}$ & $\dfrac{1}{3}$ & $\dfrac{13}{48}$ & 0.2917 & 0.2951 & 0.2865& 0.2917 & 0.2905\\
    $v_4$ & $\dfrac{1}{4}$ & $\dfrac{5}{24}$ & $\dfrac{1}{6}$ & 0.2083 & 0.1910 & 0.1910 & 0.1962 & 0.1924\\
    \hline
\end{tabular}
\egroup
\begin{itemize}
    \item Looks okay, but the values don't quite converge
\end{itemize}
\end{frame}

\begin{frame}[t]
\frametitle{Introducing a Damping factor}
\begin{outline}
    \1 At some point, our user who is randomly clicking links will eventually stop clicking links
    \1 At each iteration we consider a constant probability\\ $d :=$ the probability that our user stops traversing the graph
        \2 Various studies have settled on $d\approx 0.85$
    \1 For an arbitrary graph:
\end{outline}
\begin{mdframed}[backgroundcolor=blue!20]
    \begin{math}
        PR(v_i) = \dfrac{1-d}{|V|} + d(c_1PR(v_1) + c_2PR(v_2) + c_3PR(v_3))
    \end{math}
\end{mdframed}
\begin{outline}
    \1 $c_n = \dfrac{1}{|V_n|}$ if $i \in V_n$, and 0 else. 
        \2 If $n$ cites $i$, then $n$ contributes its equally distributed value to $i$. If $n$ doesn't cite $i$, $n$ contributes 0 to $i$.
    \1 If $|V_j| = 0$, we use $|V|$ (random jump from sinks)
\end{outline}
\end{frame}

\begin{frame}
\frametitle{Iterations w/ Damping}
\bgroup
\def\arraystretch{2.5}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
    \hline
    $PR$ & 0 & 1 & 2 & 3 & 4 & 5 & 6 \\%& 7\\
    \hline
    $v_1$ & $\dfrac{1}{4}$ & 0.3562 & 0.4014 & 0.3502 & 0.3720 & 0.3697 & 0.3664\\% & 0.3689\\
    $v_2$ & $\dfrac{1}{4}$ & 0.1083 & 0.1384 & 0.1512 & 0.1367 & 0.1429 & 0.1422\\% & 0.1413\\
    $v_3$ & $\dfrac{1}{4}$ & 0.3208 & 0.2757 & 0.2885 & 0.2903 & 0.2864 & 0.2884\\% & 0.2880\\
    $v_4$ & $\dfrac{1}{4}$ & 0.2146 & 0.1845 & 0.2101 & 0.2010 & 0.2010 & 0.2030\\% & 0.2018\\
    \hline
\end{tabular}
\egroup
\end{frame}

\section{Applications}
\begin{frame}[t]
    \frametitle{Applications}
    \begin{outline}
        \1 PageRank is perhaps the most famous search ranking algorithm. Googles high-quality search engine results are directly correlated to PageRank
        \1 There are a remarkable wide variety of applications of the PageRank algorithm that apply to non-search engine contexts.
        \1 Its simplicity and elegance allow PageRank to be a more general and powerful tool.
        \1 Let's look at the applications of PageRank and its connection to Twitter.

    \end{outline}
\end{frame}

\begin{frame}[t]
    \frametitle{Twitter}
    \begin{outline}
        \1 In 2010, Twitter was lagging behind and was lacking a user recommendation service. 
        \1 This was perceived both externally and internally as a critical gap in Twitter’s product offerings, so quickly launching a high-quality product was a top priority.
        \1 Twitter is unique because of the asymmetric nature of the following relationship—a user can receive messages from another without reciprocation. 
        \1 This differs substantially from other social networks such as Facebook or LinkedIn, where social ties can only be established with the consent of both participating members.
    \end{outline}
\end{frame}

\begin{frame}[t]
    \frametitle{Introducing PageRank}
    \begin{outline}
        \1 This works well with PageRank because we can determine outbound and inbound links.
        \1 A user $u$ is likely to follow those who are followed by users that are similar to $u$. 
        \1 These users are in turn similar to $u$ if they follow the same (or similar) users.
        \1 Therefore using Page Rank, Twitter is able to offer unique recommendations for users. 
        \1 By analyzing who the user follows and who those users follow, the PageRank algorithm will allow Twitter to make specific recommendations for each user. 
        \1 Essentially, the more outbound links that an account receives correlate to a higher PageRank score.        
    \end{outline}
\end{frame}
%\begin{frame}
%\frametitle{Visual Representation}
%\begin{center}
%    \includegraphics[width=0.6\textwidth]{weighted.png}
%\end{center}
%\begin{outline}
%    \1 In this case, all nodes have a PageRank value of 1.
%\end{outline}
%\end{frame}

%\begin{frame}
%\frametitle{Transition Matrix}
%\begin{columns}
%    \begin{column}{0.5\textwidth}
%        \centering
%        \includegraphics[width=\textwidth]{weighted.png}
%    \end{column}
%    \begin{column}{0.5\textwidth}
%        \centering
%        $T = \begin{pmatrix}
%            0 & 1/3 & 1/3 & 1/3\\
%            0 & 0 & 1/2 & 1/2\\
%            1 & 0 & 0 & 0\\
%            1/2 & 0 & 1/2 & 0\\
%        \end{pmatrix}$
%    \end{column}
%\end{columns}
%\begin{outline}
%    \1 All entries of the transition matrix are non-negative
%    \1 If $v_i$ has at least one outgoing edge, the sum of the entries in row $i$ is 1
%        \2 Else, the sum is 0.
%\end{outline}
%\end{frame}


\end{document}