\documentclass{beamer}

\title{PageRank}
\author{Ben Burns, Dan Magazu, Lucas Chagas, \\Thomas Webster, Trung Do}
\date{Fall 2021}

\usepackage{outlines}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{color, xcolor, mdframed}

\graphicspath{{./images}}

\addtobeamertemplate{navigation symbols}{}{
    \usebeamerfont{footline}
    \usebeamercolor[fg]{footline}
    \hspace{1em}
    \insertframenumber/\inserttotalframenumber
}

%\AtBeginSection[ ]
%{
%\begin{frame}{Outline}
%    \tableofcontents[currentsection]
%\end{frame}
%}

\begin{document}

\frame{\titlepage}

\begin{frame}
\frametitle{Table of Contents}
\tableofcontents
\end{frame}

\section{Background}
\begin{frame}[t]{PageRank}
\begin{outline}
    \1 PageRank is the algorithm to determine the importance of a website relatively to all other websites. The algorithm ranks the importance of website $w,$ i.e., PR($w$), based on the number of links points to website w and the \emph{quality} of each pointing link from the other source website. 

    \1 \textbf{The underlying assumption}: More important website are likely to receive more links from other website. Since the algorithm measures the relative popularity ("ranking") between all websites, websites with higher ranking score are ranked higher. The sum of all ranking score equals 1 (will see why later).
\end{outline}
\end{frame}

\section{Formalizing PageRank}
\begin{frame}[t]{Formalizing the PageRank problem}
\begin{outline}
    \begin{columns}
        \begin{column}{0.5\textwidth}
            \includegraphics[width=\textwidth]{unweighted.png}
        \end{column}
        \begin{column}{0.5\textwidth}
            As a graph: Each website is represented by a node assigned with a PageRank value, denoted by PR(w). If a website w has a link to another website v (meaning there are an outbound link from w and an inbound link to v), then there is a directed edge from node w to node v. Multiple links from w to v is treated as a single edge from node w to v, and all self-links from a website to itself are ignored. Thus, this is a node-weighted, simple, no self-loop directed graph.
        \end{column}
    \end{columns}
\end{outline}
\end{frame}

\begin{frame}
\frametitle{Edge Weights}
\begin{columns}
    \begin{column}{0.5\textwidth}
        \includegraphics[width=\textwidth]{weighted.png}
    \end{column}
    \begin{column}{0.5\textwidth}
        This edge has its weight equal to PR(*w*) divided by the total number of outbound links of $w$, L($w$). Then recipient node $v$ "receives" the PageRank value of $w$, adding to its own value, i.e., PR($v$) += PR($w$)/L($w$). 
        
        In another words, for a given node in the graph:

        \textbf{An outbound link} will "give" away the PR value of the source node to the recipient node.  

        \textbf{An inbound link} will add the PR value from the source node to the recipient node.
    \end{column}
\end{columns}
\end{frame}

\section{Ways to Solve}
\begin{frame}[t]{Perspectives for Solving}
    \begin{itemize}
        \setlength\itemsep{1em}
        \item There are two ways to understand the problem:
        \item[1)] as an Eigenvector problem
        \item[2)] as a probability problem
        \item Both perspectives use linear algebra 
    \end{itemize}
\end{frame}

%\begin{frame}{Adjacency Matrix}
%\begin{columns}
%    \begin{column}{0.5\textwidth}
%        \centering
%        \includegraphics[width=\textwidth]{unweighted.png}
%    \end{column}
%    \begin{column}{0.5\textwidth}
%        \centering
%        {\Large$A = \begin{pmatrix}
%            0 & 1 & 1 & 1\\
%            0 & 0 & 1 & 1\\
%            1 & 0 & 0 & 0\\
%            1 & 0 & 1 & 0\\
%        \end{pmatrix}$}
%    \end{column}
%\end{columns}
%\begin{outline}
%    \1 No self loops means the main diagonal is all zeros
%\end{outline}
%\end{frame}

\subsection{Probability Method}
\begin{frame}[t]{Probability Problem}
    \begin{outline}
        \1 In the underlying assumption, the ranking of website is the relative relationship between all websites. 
        \1 The ranking of a website $w$ can be viewed as the probability that a random surfer opens the browser, starts following links, and ends up in that website $w$.
        \1 If the random surfer are currently at node $w_1$, for example, then there is a 1/3 chance he would go to node $w_2$, 1/3 chance he would go to node $w_3$, 1/3 chance he would go to node $w_4$. 
        \1 We can model this surfing process as a random walk on graph. 
    \end{outline}
\end{frame}

\begin{frame}[t]{System of Equations}
    \begin{outline}
        \1 Analyzing the relationship between 4 nodes in the example, 
        
        \begin{center}
            \includegraphics[width=0.35\textwidth]{unweighted.png}    
        \end{center}

        we get the system:
    
        \begin{center}
            $\begin{cases}
                x_1 = 1 \cdot x_3 + \dfrac{1}{2}\cdot x_4&\\[6pt]
                x_2 = \dfrac{1}{3}\cdot x_1&\\[6pt]
                x_3 = \dfrac{1}{3}\cdot x_1 + \dfrac{1}{2}\cdot x_2 + \dfrac{1}{2}\cdot x_4&\\[6pt]
                x_4 = \dfrac{1}{3}\cdot x_1 + \dfrac{1}{2}\cdot x_2&\\[6pt]
            \end{cases}$
        \end{center}
    \end{outline}
\end{frame}

\subsection{Eigenvector Method}
\begin{frame}[t]{Eigenvector Problem}
\begin{outline}
    \1 \textbf{Why eigenvector}: By assumption, the PageRank system is a relative ranking system between all nodes in the graph. 
    \1 Let us denote the entries of vector $v$, $x_i$, as the ranking score of page $w_i$, $x_i = PR(w_i)$:

    \begin{center}
        $v = \begin{bmatrix}
            x_1\\
            x_2\\
            x_3\\
            x_4\\
        \end{bmatrix}$
    \end{center}
    \1 Thus we can translate the problem into the eigenvector problem:
    \begin{align*}
        A\cdot \begin{bmatrix}
            x_1\\
            x_2\\
            x_3\\
            x_4\\
        \end{bmatrix} &= \begin{bmatrix}
            x_1\\
            x_2\\
            x_3\\
            x_4\\
        \end{bmatrix}
    \end{align*}
\end{outline}
\end{frame}



%\begin{frame}[t]{Solving for Eigenvector}
%    \begin{outline}
%            \2 Find an eigenvector $v$ corresponding to the eigenvalue 1 of the following system:
%    \end{outline}
%\end{frame}

\begin{frame}[t]{Considerations with the Eigenvalue}
\begin{outline}
    \1 If we choose to solve by the eigenvector problem, there are a few things to address
    \1 The conditions to rigorously use the eigenvector method will be defined below. For now, we can solve for the eigenvector corresponding to the eigenvalue 1:
    \begin{align*}
        c\cdot \begin{bmatrix}
            12\\ 4\\ 9\\ 6\\
        \end{bmatrix}
    \end{align*}
    \1 Every vector in the above format is the eigenvector corresponding to eigenvalue 1. 
    \1 We choose $c$ such that the sum of all entries in this vector equals 1 (we later refer to it as "the probabilistic eigenvector corresponding to the eigenvalue 1")
\end{outline}
\end{frame}

\begin{frame}[t]{Power Iteration Method}
\begin{outline}
    \1 Want to determine the eigenvector of the square matrix $A$
    \1 Start out with 
    \begin{center}
        $\vec{v_0} = \begin{bmatrix}
            0.25 \\ 0.25 \\ 0.25 \\ 0.25 \\
        \end{bmatrix}$
    \end{center}
    as a candidate eigenvector corresponding to eigenvalue of 1
    \1 Calculate $\vec{v_1} = A\vec{v_0}$ to get a new vector
    \1 Continue to iterate until $v_k$ converges 
    \1 Two questions:
        \2 Will $v_k$ always converge?
        \2 Will $v_k$ give us any useful information about the ranking of websites?
\end{outline}
\end{frame}

\section{Treating Problematic Edge Cases}
\begin{frame}[t]{Spider Traps}
\begin{outline}
    \1 Our random walker gets stuck in a portion of the graph leading to most of the “importance” to flow into subgraph where the walker is stuck
    \1 Example: what happens when we run power iteration on this web graph? (notice that the random walker will get stuck on page $m$)
    \begin{center}
        \includegraphics[width=0.6\textwidth]{spider.png}
    \end{center}
\end{outline}
\end{frame}

\begin{frame}[t]{Spider Trap Continued}
\begin{outline}
    \1 Power iteration successfuly converges! So we're done right?
    \1 Wrong. Page $m$ receives a rank of $r_m = 1$ while the rest of the pages are of no importance
    \1 From the random walker's perspective this makes sense. But this is not what we want.
    
    \begin{center}
        \includegraphics[width=0.8\textwidth]{spider1b.png}
    \end{center}
\end{outline}
\end{frame}
\begin{frame}{Another Spider Trap}
\begin{columns}
    \begin{column}{0.5\textwidth}
        \parskip=1em
        Another example:

    Page a starts with an importance
    of 1 and passes it page $b$ in the first
    iteration. Then $b$ passes 1 to $a, \cdots$
    And this process continues 
    indefinitely.

    We fail to converge!
    \parskip=0em
    \end{column}
    \begin{column}{0.5\textwidth}
        \includegraphics[width=\textwidth]{spider2a.png}    
        \includegraphics[width=\textwidth]{spider2b.png}    
    \end{column}
\end{columns}
\end{frame}
\begin{frame}[t]{The Solution to the Spider Traps}
    \begin{itemize}
        \item At each time step, the random surfer chooses 1 of 2 options:
        \item With some probability $\beta$, the surfer will follow a random link
        \item With the remaining probability 1 -$\beta$ , the surfer will jump to random page
        \item This means within a few time steps, the surfer will teleport out of the spider trap within a few time steps
    \end{itemize}
\end{frame}
    
\begin{frame}[t]{Dead Ends}
\begin{columns}
    \begin{column}{0.5\textwidth}
        \begin{outline}
            \1 The random walker encounters a web page without any outbound links leaving them nowhere to go.
            \1 Example:
            We converge but power iteration
            tells us that both page a and b are
            unimportant!
        \end{outline}
    \end{column}
    \begin{column}{0.5\textwidth}
        \includegraphics[width=\textwidth]{deadenda.png}
        \includegraphics[width=\textwidth]{deadendb.png}
    \end{column}
\end{columns}
\end{frame}
\begin{frame}[t]{The Solution to Dead Ends}
\begin{outline}
\1 Dead end problem: the pages that have zero scores, which leads to their PageRank score not getting distributed to any other page in the graph, not pointing to any other graph
\1 After running the power iteration, after several iterations, it will converge towards zero, which leads to the PageRank score of a particular node not being passed down and leaking out of the system
\1 How to solve the Dead Ends Problem:
        \2 Solution: Always Teleports
        \2 If a node has no outgoing links, when we reach that node, we teleport with a probability of 1
        \2 this means that whenever we reach the dead-end node, we will always jump out and reach somewhere else
\end{outline}
\end{frame}
    
\begin{frame}[t]{Why Do Teleports Solve the Problem?}
\begin{outline}
\1 For any start vector, the power method applied to a Markov transition matrix A will converge to a unique positive stationary vector as long as A is stochastic, irreducible, and aperiodic.
\end{outline}
\end{frame}
   
\begin{frame}[t]{Stocastic}
    Stochastic: Every column in the transition matrix sums to 1
\end{frame}

\begin{frame}[t]{Aperiodic}
    Aperiodic: A chain is periodic if there exist $k > 1$ such that the interval between two visits to some state s is always a multiple of $k$
    
\end{frame}

\begin{frame}[t]{Irreducible}
    Irreducible: From any state, there is a non-zero probability of going from any one state to another
\end{frame}

\begin{frame}[t]{The PageRank equation}
\begin{outline}
\1 Google's solution makes the Markov Transition matrix stochastic, aperiodic, and irreducible.

\1 PageRank equation:

\begin{mdframed}[backgroundcolor=blue!20]
    \begin{center}
        $r_j = \sum\limits_{i\to j}\beta \dfrac{r_i}{d_i} + (1-\beta)\dfrac{1}{n}$
    \end{center}
\end{mdframed}

\2 The summation is the sum of all of the importance of node $I$ that point to it where $r_j$ and $r_i$ is the probability that the random surf is on this node.
\2 This is divided by $d_i$, which is the probability that the random surf traverses the link when iterating towards $j$. This only happens with probability $\beta$, when the surfer decides to follow the link.
\2 The $(1-\beta)/n$ represents when the random walkers decide to jump somewhere else, using the probability ($1-\beta) \cdot 1/n$, where $n$ is the number of nodes in the entire network.
\end{outline}
\end{frame}

\section{Google's Implementation}
\begin{frame}[t]{The Google Matrix}
    \begin{mdframed}[backgroundcolor=blue!20]
        \begin{center}
            $A = \beta M + (1-\beta)\dfrac{1}{n}e\cdot e^T$
        \end{center}
    \end{mdframed}
    \begin{itemize}
       
        \item Matrix A, also known as the google matrix, is the transition matrix multiplied with ß(for random jumps) plus the probabilities due to random jumps, known as (1-ß). 
    
    
    \item This is then multiplied by e, the outer product of a vector that is of all 1s.
    \end{itemize}
    \end{frame}

\begin{frame}{Using the Google Matrix Example}
    \begin{center}
        \includegraphics[width=\textwidth]{example.jpg}   
    \end{center}
\end{frame}

\end{document}